# configs/config.yaml

# wandb
wandb:
  api_key: 535c3c99189d95a763cef3eaf7e316f0b9417510
  team_name: CV_16_Segmantation
  project_name: "Hand Bone Segmentation"
  experiment_detail: "config_lora"


# image resize
image_size: &image_size 512 #&는 앵커로, 특정값은 별칭(*)으로 저장하여 yaml 에서 해당값을 여러번 재사용할 수 있게함.

max_epoch: &max_epoch 40


# 모델명 및 사전 학습 여부
model:
  name: DeepLabV3PlusModel_LoRA # 모델 이름
  parameters:         # 모델 파라미터 섹션 -> 이는 segmentation_models_pytorch 공식 라이브러리의 github에서 확인.
    encoder_name: efficientnet-b0
    encoder_weights: imagenet
    classes: 29

lora:
  use: true
  params:
    r: 8
    lora_alpha: 16
    lora_dropout: 0.1
    # target_modules: "_blocks.\\d+.(_expand_conv|_depthwise_conv|_project_conv)$"
    target_modules: "endcoder._blocks.\\d+._project_conv$"
    modules_to_save: ["decoder", "encoder._conv_head"]

# train 매개변수 설정
train:
  max_epoch: *max_epoch
  image_root: "data/train/DCM"
  label_root: "data/train/outputs_json"
  train_batch_size: 8
  num_workers : 16
  lr: 1e-3
  weight_decay: 1e-6
  channel_1: false # 채널 1개로 학습할시 true


# validation 관련 인자
validation:
  val_fold: 0
  val_interval: 5
  num_workers: 8
  threshold: 0.5
  val_batch_size: 4

# 스케줄러 관련 설정
scheduler:
  name: CosineAnnealingLR  # 스케줄러 이름
  parameters:             # 스케줄러 파라미터
    T_max: *max_epoch
    eta_min: 1e-6

# loss 관련설정
loss:
  name: BCEWithLogitsLoss
  parameters: {} # dict 형태로 작성해야함
    

# transform 관련
transform:
  Resize:
    width: *image_size #별표(*)는 이미지 별칭으로, 재사용하기 위해 사용함
    height: *image_size
  
  HorizontalFlip:
    use: false
    p: 0.5

  Rotate:
    use: false
    limit: 45 #특정 변환의 최대값 제한 설정.
    p: 0.7

  RandomBrightnessContrast:
    brightness_limit: 0.2
    contrast_limit: 0.2
    p: 0.5


# random seed값
seed: 42

# Output paths
output:
  checkpoint_dir: "../checkpoints"
  name: "config_lora.pt"
  output_csv: "../output/config_lora.csv"


# checkpoint 저장 경로
save_dir: ./checkpoints/config_lora

